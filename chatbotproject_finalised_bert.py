# -*- coding: utf-8 -*-
"""ChatbotProject_Finalised_BERT

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15E2vj-JCkS7C88froSZj4gvLIJPBGMBJ
"""

import pandas as pd
import numpy as np
import torch
from transformers import BertForQuestionAnswering
from transformers import BertTokenizer

def toSentence(tokens):
  str = ''
  for word in tokens:
    str = str + word + " "
  return str

#  Importing Bert For Question Answering class from transformers library.
model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')
tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')

def question_answer(question, paragraph):

    max_tokens_length = 512
    sep_tokens = 2

    total_input_ids = tokenizer.encode(question, paragraph)
    # print("Total_input_ids are: ", len(total_input_ids))

    sep_1_idx = total_input_ids.index(tokenizer.sep_token_id) #index of the first [SEP] token
    # print("The first [SEP] token is at the index: ", sep_1_idx)

    sep = [total_input_ids[sep_1_idx]]
    question_idx = total_input_ids[0:sep_1_idx]
    # print("Length of the Question with CLS token is: ", len(question_idx))
    
    step_size_for_loop = max_tokens_length-len(question_idx)-sep_tokens-50
    

    for i in range(sep_1_idx+1, len(total_input_ids)-1, step_size_for_loop):              #Eg. array = [CLS:0, .., SEP:12, ..,SEP:9999], Therefore step size = 512-12-2-50(buffer)= 448
      # print("i is: ", i)

      j = min(i +step_size_for_loop +50, len(total_input_ids))
      # print("j is: ", j)

      paragraph_idx = total_input_ids[i : j]
      # print("Length of the paragraph: ", len(paragraph_idx))

      input_ids = []
      input_ids.extend(question_idx)
      input_ids.extend(sep)
      input_ids.extend(paragraph_idx)
      input_ids.extend(sep)
      # print("Total token length of the input_ids: ", len(input_ids))
      
      #string version of tokenized ids
      tokens = tokenizer.convert_ids_to_tokens(input_ids)
      # print("The word-tokens are: ", tokens)

      #segment IDs
      sep_idx = input_ids.index(tokenizer.sep_token_id)
      num_seg_a = sep_idx+1
      num_seg_b = len(input_ids) - num_seg_a
      
      #list of 0s and 1s for segment embeddings
      segment_ids = [0]*num_seg_a + [1]*num_seg_b
      assert len(segment_ids) == len(input_ids)
      
      #model output using input_ids and segment_ids
      output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))
    
      #reconstructing the answer
      answer_start = torch.argmax(output.start_logits)
      answer_end = torch.argmax(output.end_logits)
      answer = tokens[answer_start]
      # print(answer)

      if answer_end >= answer_start:
          # print("in if")
          answer = tokens[answer_start]
          for i in range(answer_start+1, answer_end+1):
              if tokens[i][0:2] == "##":
                  answer += tokens[i][2:]
              else:
                  answer += " " + tokens[i]
          # break 

      # print(answer)
      # print(answer.split()[0])
      
      if(answer.split()[0] != '[CLS]' and answer.split()[0] != '[SEP]'):
        # print("in 2nd if")
        break
                     
      if (answer.startswith("[CLS]") or answer.startswith("[SEP]")):
        # print("in 3rd if)")
        if(i >= len(total_input_ids)- step_size_for_loop):
          # print("in 4th if")
          answer = "Unable to find the answer to your question."
        else:
          # print("in else")
          continue
      
    print("\nPredicted answer:\n{}".format(answer.capitalize()))

def bert_computation(question, paragraph):
    question_answer(question, paragraph)
    
  
#   while True:
#     question_answer(question, paragraph)
    
#     flag = True
#     flag_N = False
    
#     while flag:
#         response = input("\nDo you want to ask another question based on this text (Y/N)? ")
#         if response[0] == "Y":
#             question = input("\nPlease enter your question: \n")
#             flag = False
#         elif response[0] == "N":
#             print("\nBye!")
#             flag = False
#             flag_N = True
            
#     if flag_N == True:
#         break

